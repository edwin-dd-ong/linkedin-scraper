{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6840a0ed-1610-4763-85a0-e19c81a5c3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process SpawnPoolWorker-7:\n",
      "Process SpawnPoolWorker-9:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/edwin/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/edwin/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/edwin/opt/anaconda3/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/edwin/opt/anaconda3/lib/python3.9/multiprocessing/queues.py\", line 368, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'scrape_profile' on <module '__main__' (built-in)>\n",
      "  File \"/Users/edwin/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/edwin/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/edwin/opt/anaconda3/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/edwin/opt/anaconda3/lib/python3.9/multiprocessing/queues.py\", line 368, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'scrape_profile' on <module '__main__' (built-in)>\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "# Function to log in to LinkedIn\n",
    "def linkedin_login():\n",
    "    driver.get(\"https://www.linkedin.com/login\")\n",
    "    # Pause for manual security code input\n",
    "    print(\"Please enter the security code manually.\")\n",
    "    input(\"Press Enter in this console once the code is entered and you're logged in...\")\n",
    "\n",
    "\n",
    "# Function for MultiProcessing\n",
    "def scrape_profiles_multiprocessing(profiles, num_processes):\n",
    "    with Pool(num_processes) as pool:\n",
    "        results = pool.map(scrape_profile, profiles)\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "# Function to scrape profile information\n",
    "def scrape_profile(url):\n",
    "    driver = webdriver.Chrome()\n",
    "    linkedin_login()\n",
    "     \n",
    "    driver.get(url)\n",
    "    time.sleep(5)  # Wait for profile page to load\n",
    "    data = {'linkedin_url': url}\n",
    "    \n",
    "    try:\n",
    "        data['name'] = driver.find_element(By.CSS_SELECTOR, \"h1\").text\n",
    "        experience_element = driver.find_element(By.XPATH, '//div[@id=\"experience\"]/..')\n",
    "        companies = get_organizations(experience_element, url)\n",
    "        for i, company in enumerate(companies):\n",
    "            data[f'company {i+1}'] = company\n",
    "        education_element = driver.find_element(By.XPATH, '//div[@id=\"education\"]/..')\n",
    "        schools = get_organizations(education_element, url)\n",
    "        for i, school in enumerate(schools):\n",
    "            data[f'school {i+1}'] = school\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting data for profile: {url} | Error: {e}\")\n",
    "    driver.quit()\n",
    "    return data\n",
    "\n",
    "\n",
    "# Function to get experiences or education\n",
    "def get_organizations(parent_element, url):\n",
    "    try:\n",
    "        parent_element.find_element(By.XPATH, './/a[contains(@id,\"see-all\") and @target=\"_self\"]').click()\n",
    "        time.sleep(5)  # Wait for page to load\n",
    "        parent_element = driver.find_element(By.CLASS_NAME, \"scaffold-layout__main\")\n",
    "        print(\"clicked on see all experiences/education\")\n",
    "    except Exception as e:\n",
    "        # If it fails, just print the error and move on\n",
    "        print(f\"Could not click 'See All Experiences/Education'\")\n",
    "    logo_elements = parent_element.find_elements(By.XPATH, './/a[contains(@href,\"company\") and @target=\"_self\"]')\n",
    "    href_links = []\n",
    "    for element in logo_elements:\n",
    "        # Get the href attribute of each element and append it to the href_links list\n",
    "        href_links.append(element.get_attribute(\"href\"))\n",
    "    href_links = list(set(href_links))\n",
    "    organizations = []\n",
    "    for link in href_links:\n",
    "        driver.get(link)\n",
    "        time.sleep(3)  # Wait for page to load\n",
    "        try:\n",
    "            # Attempt to find the h1 element\n",
    "            h1_element = driver.find_element(By.CSS_SELECTOR, \"h1\")\n",
    "            organizations.append(h1_element.text)\n",
    "        except Exception as e:\n",
    "            # If h1 element is not found, do nothing\n",
    "            pass\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "    return organizations\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
